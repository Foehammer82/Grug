"""add timedelta to event

Revision ID: fb3d6a131d9a
Revises: 9cd29399a009
Create Date: 2024-05-13 22:48:51.515813

"""
from alembic import op
import sqlalchemy as sa
import sqlmodel
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'fb3d6a131d9a'
down_revision = '9cd29399a009'
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('job_results', schema=None) as batch_op:
        batch_op.drop_index('ix_job_results_expires_at')
        batch_op.drop_index('ix_job_results_finished_at')

    op.drop_table('job_results')
    op.drop_table('tasks')
    with op.batch_alter_table('schedules', schema=None) as batch_op:
        batch_op.drop_index('ix_schedules_next_fire_time')
        batch_op.drop_index('ix_schedules_task_id')

    op.drop_table('schedules')
    op.drop_table('metadata')
    with op.batch_alter_table('jobs', schema=None) as batch_op:
        batch_op.drop_index('ix_jobs_task_id')

    op.drop_table('jobs')
    with op.batch_alter_table('events', schema=None) as batch_op:
        batch_op.add_column(sa.Column('event_repeat', sa.Interval(), nullable=True))

    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('events', schema=None) as batch_op:
        batch_op.drop_column('event_repeat')

    op.create_table('jobs',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('task_id', sa.VARCHAR(length=500), autoincrement=False, nullable=False),
    sa.Column('args', postgresql.BYTEA(), autoincrement=False, nullable=False),
    sa.Column('kwargs', postgresql.BYTEA(), autoincrement=False, nullable=False),
    sa.Column('schedule_id', sa.VARCHAR(length=500), autoincrement=False, nullable=True),
    sa.Column('scheduled_fire_time', sa.VARCHAR(length=32), autoincrement=False, nullable=True),
    sa.Column('jitter', sa.BIGINT(), autoincrement=False, nullable=True),
    sa.Column('start_deadline', sa.VARCHAR(length=32), autoincrement=False, nullable=True),
    sa.Column('result_expiration_time', sa.BIGINT(), autoincrement=False, nullable=True),
    sa.Column('created_at', sa.VARCHAR(length=32), autoincrement=False, nullable=False),
    sa.Column('started_at', sa.VARCHAR(length=32), autoincrement=False, nullable=True),
    sa.Column('acquired_by', sa.VARCHAR(length=500), autoincrement=False, nullable=True),
    sa.Column('acquired_until', sa.VARCHAR(length=32), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name='jobs_pkey')
    )
    with op.batch_alter_table('jobs', schema=None) as batch_op:
        batch_op.create_index('ix_jobs_task_id', ['task_id'], unique=False)

    op.create_table('metadata',
    sa.Column('schema_version', sa.INTEGER(), autoincrement=False, nullable=False)
    )
    op.create_table('schedules',
    sa.Column('id', sa.VARCHAR(length=500), autoincrement=False, nullable=False),
    sa.Column('task_id', sa.VARCHAR(length=500), autoincrement=False, nullable=False),
    sa.Column('trigger', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.Column('args', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.Column('kwargs', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.Column('coalesce', postgresql.ENUM('earliest', 'latest', 'all', name='coalescepolicy'), autoincrement=False, nullable=False),
    sa.Column('misfire_grace_time', sa.BIGINT(), autoincrement=False, nullable=True),
    sa.Column('max_jitter', sa.BIGINT(), autoincrement=False, nullable=True),
    sa.Column('next_fire_time', sa.BIGINT(), autoincrement=False, nullable=True),
    sa.Column('next_fire_time_utcoffset', sa.SMALLINT(), autoincrement=False, nullable=True),
    sa.Column('last_fire_time', sa.VARCHAR(length=32), autoincrement=False, nullable=True),
    sa.Column('acquired_by', sa.VARCHAR(length=500), autoincrement=False, nullable=True),
    sa.Column('acquired_until', sa.VARCHAR(length=32), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name='schedules_pkey')
    )
    with op.batch_alter_table('schedules', schema=None) as batch_op:
        batch_op.create_index('ix_schedules_task_id', ['task_id'], unique=False)
        batch_op.create_index('ix_schedules_next_fire_time', ['next_fire_time'], unique=False)

    op.create_table('tasks',
    sa.Column('id', sa.VARCHAR(length=500), autoincrement=False, nullable=False),
    sa.Column('func', sa.VARCHAR(length=500), autoincrement=False, nullable=True),
    sa.Column('job_executor', sa.VARCHAR(length=500), autoincrement=False, nullable=False),
    sa.Column('max_running_jobs', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('misfire_grace_time', sa.BIGINT(), autoincrement=False, nullable=True),
    sa.Column('running_jobs', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name='tasks_pkey')
    )
    op.create_table('job_results',
    sa.Column('job_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('outcome', postgresql.ENUM('success', 'error', 'missed_start_deadline', 'cancelled', name='joboutcome'), autoincrement=False, nullable=False),
    sa.Column('finished_at', sa.VARCHAR(length=32), autoincrement=False, nullable=True),
    sa.Column('expires_at', sa.VARCHAR(length=32), autoincrement=False, nullable=False),
    sa.Column('exception', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.Column('return_value', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('job_id', name='job_results_pkey')
    )
    with op.batch_alter_table('job_results', schema=None) as batch_op:
        batch_op.create_index('ix_job_results_finished_at', ['finished_at'], unique=False)
        batch_op.create_index('ix_job_results_expires_at', ['expires_at'], unique=False)

    # ### end Alembic commands ###
